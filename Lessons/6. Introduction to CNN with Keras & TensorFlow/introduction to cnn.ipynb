{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b5f8b74",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Introduction to CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a96805",
   "metadata": {},
   "source": [
    "CNN Microscopy Segmentation \n",
    "\n",
    "This notebook teaches **beginner CNN segmentation** for microscopy images.\n",
    "\n",
    "**Core goals:**\n",
    "- Learn how to create masks using OpenCV\n",
    "- Train a CNN for multi-class segmentation (TensorFlow)\n",
    "- Evaluate using Dice & IoU\n",
    "- Improve outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8076a646",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "# Import Google Drive interface so we can access datasets stored there\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive at the specified path\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05521a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "## 2. Import Required Libraries\n",
    "\n",
    "# Operating system utilities (file paths, directory listing)\n",
    "import os\n",
    "\n",
    "# Numerical computing\n",
    "import numpy as np\n",
    "\n",
    "# Image processing with OpenCV\n",
    "import cv2\n",
    "\n",
    "# Plotting and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TensorFlow / Keras for CNNs\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Metrics helpers\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bd09bb",
   "metadata": {},
   "source": [
    "## 3. Dataset Structure\n",
    "\n",
    "Expected folder structure:\n",
    "```\n",
    "Microscopy_Dataset/\n",
    " ├── images/   (.JPG microscopy images)\n",
    " └── masks/    (.png masks – generated if missing)\n",
    "```\n",
    "\n",
    "Important: Masks **do not originally exist** and must be created using OpenCV.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8a37fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define base directory containing images and masks\n",
    "BASE_DIR = '/content/drive/MyDrive/CNN_Microscopy'\n",
    "\n",
    "# Path to raw microscopy images\n",
    "IMAGE_DIR = os.path.join(BASE_DIR, 'images')\n",
    "\n",
    "# Path where masks will be stored or loaded\n",
    "MASK_DIR = os.path.join(BASE_DIR, 'masks')\n",
    "\n",
    "# Create mask directory if it does not already exist\n",
    "os.makedirs(MASK_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca5e4a4",
   "metadata": {},
   "source": [
    "## 4. Multi-Class Mask Generation using OpenCV\n",
    "\n",
    "We generate **weak labels** using image intensity and morphology.\n",
    "\n",
    "Class definitions:\n",
    "- 0 → Background\n",
    "- 1 → Small pores\n",
    "- 2 → Large pores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242f8c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask(image_path, save_path):\n",
    "    \"\"\"\n",
    "    Generate a multi-class segmentation mask using Otsu's thresholding\n",
    "    and contour area analysis.\n",
    "    \"\"\"\n",
    "    # Load image in grayscale mode\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "    # Use Otsu's method to automatically find threshold\n",
    "    _, binary = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Initialize mask with background class (0)\n",
    "    mask = np.zeros_like(blur, dtype=np.uint8)\n",
    "    mask[binary == 255] = 2  # All pores start as class 2 (large pores)\n",
    "\n",
    "    # Separate by size using contour analysis\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area < 50:  # Small pores threshold\n",
    "            cv2.drawContours(mask, [contour], -1, 1, -1)\n",
    "        # else: stays as 2 (large pores)\n",
    "\n",
    "    # Morphological opening to remove noise\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Save generated mask\n",
    "    cv2.imwrite(save_path, mask)\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ca6ef1",
   "metadata": {},
   "source": [
    "## 4.1 Analyze Sample Image Intensity Distribution\n",
    "\n",
    "### Check if images directory exists and has files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104958ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(IMAGE_DIR):\n",
    "    print(f\"ERROR: Image directory not found at {IMAGE_DIR}\")\n",
    "    print(\"Please update BASE_DIR to point to your dataset location\")\n",
    "else:\n",
    "    image_files = [f for f in os.listdir(IMAGE_DIR) if f.endswith('.JPG')]\n",
    "\n",
    "    if len(image_files) == 0:\n",
    "        print(f\"ERROR: No .JPG files found in {IMAGE_DIR}\")\n",
    "    else:\n",
    "        # Load first sample image\n",
    "        sample_img = cv2.imread(os.path.join(IMAGE_DIR, image_files[0]), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        plt.figure(figsize=(12, 4))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(sample_img, cmap='gray')\n",
    "        plt.title('Sample Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.hist(sample_img.ravel(), bins=256, range=[0, 256])\n",
    "        plt.title('Intensity Histogram')\n",
    "        plt.xlabel('Pixel Intensity')\n",
    "        plt.ylabel('Count')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"Min intensity: {sample_img.min()}\")\n",
    "        print(f\"Max intensity: {sample_img.max()}\")\n",
    "        print(f\"Mean intensity: {sample_img.mean():.1f}\")\n",
    "        print(f\"Found {len(image_files)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c62d6eb",
   "metadata": {},
   "source": [
    "## 4.2 Generate All Masks\n",
    "\n",
    "### Generate masks for all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328c9104",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating masks...\")\n",
    "mask_count = 0\n",
    "for fname in os.listdir(IMAGE_DIR):\n",
    "    if fname.endswith('.JPG'):\n",
    "        img_path = os.path.join(IMAGE_DIR, fname)\n",
    "        mask_path = os.path.join(MASK_DIR, fname.replace('.JPG', '.png'))\n",
    "\n",
    "        # Generate mask if it doesn't exist\n",
    "        if not os.path.exists(mask_path):\n",
    "            generate_mask(img_path, mask_path)\n",
    "            mask_count += 1\n",
    "\n",
    "print(f\"Generated {mask_count} new masks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f0a3ad",
   "metadata": {},
   "source": [
    "## 4.3 Visualize Generated Masks\n",
    "\n",
    "### Visualize a few masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbcbec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = [f for f in os.listdir(IMAGE_DIR) if f.endswith('.JPG')][:3]\n",
    "\n",
    "if len(image_files) > 0:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "    for i, fname in enumerate(image_files):\n",
    "        img = cv2.imread(os.path.join(IMAGE_DIR, fname), cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.imread(os.path.join(MASK_DIR, fname.replace('.JPG', '.png')), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        axes[0, i].imshow(img, cmap='gray')\n",
    "        axes[0, i].set_title(f'Image {i+1}')\n",
    "        axes[0, i].axis('off')\n",
    "\n",
    "        axes[1, i].imshow(mask, cmap='viridis')\n",
    "        class_counts = f'0={np.sum(mask==0)}, 1={np.sum(mask==1)}, 2={np.sum(mask==2)}'\n",
    "        axes[1, i].set_title(f'Mask {i+1}\\n({class_counts})')\n",
    "        axes[1, i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8272bd1",
   "metadata": {},
   "source": [
    "## 5. Load Images and Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee4a30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "masks = []\n",
    "\n",
    "# Iterate over each image file\n",
    "for fname in os.listdir(IMAGE_DIR):\n",
    "    if fname.endswith('.JPG'):\n",
    "        img_path = os.path.join(IMAGE_DIR, fname)\n",
    "        mask_path = os.path.join(MASK_DIR, fname.replace('.JPG', '.png'))\n",
    "\n",
    "        # Load and resize image\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "\n",
    "        # Load and resize mask\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.resize(mask, (256, 256), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        images.append(img)\n",
    "        masks.append(mask)\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X = np.array(images)[..., np.newaxis] / 255.0\n",
    "y = np.array(masks)\n",
    "\n",
    "print(f\"Loaded {len(images)} images\")\n",
    "print(f\"Image shape: {X.shape}\")\n",
    "print(f\"Mask shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b95a46",
   "metadata": {},
   "source": [
    "## 6. Train / Validation / Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0215c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d090a295",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627a07d0",
   "metadata": {},
   "source": [
    "## 7. CNN Model (TensorFlow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c0b3bb",
   "metadata": {},
   "source": [
    "# Check class distribution to detect imbalance\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "class_dist = dict(zip(unique, counts))\n",
    "print(f\"Class distribution in training data: {class_dist}\")\n",
    "\n",
    "# Calculate class weights to handle imbalance\n",
    "total_pixels = y_train.size\n",
    "class_weights = {}\n",
    "for class_id in unique:\n",
    "    # Inverse of frequency for class weighting\n",
    "    class_weights[int(class_id)] = total_pixels / (len(unique) * counts[class_id])\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "\n",
    "# Build an improved U-Net style encoder-decoder CNN for segmentation\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(256, 256, 1)),\n",
    "\n",
    "    # Encoder (downsampling)\n",
    "    layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.2),\n",
    "\n",
    "    layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.2),\n",
    "\n",
    "    layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
    "\n",
    "    # Decoder (upsampling)\n",
    "    layers.Conv2DTranspose(64, 3, strides=2, activation='relu', padding='same'),\n",
    "    layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
    "    layers.Dropout(0.2),\n",
    "\n",
    "    layers.Conv2DTranspose(32, 3, strides=2, activation='relu', padding='same'),\n",
    "    layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
    "    layers.Dropout(0.2),\n",
    "\n",
    "    # Multi-class output (3 classes)\n",
    "    layers.Conv2D(3, 1, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model with appropriate loss and metric\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5b1783",
   "metadata": {},
   "source": [
    "## 8. Train the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0309ba80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample_weight array for pixel-wise class weighting\n",
    "sample_weights_array = np.zeros_like(y_train, dtype=np.float32)\n",
    "for class_id, weight in class_weights.items():\n",
    "    sample_weights_array[y_train == class_id] = weight\n",
    "\n",
    "# Add callbacks for better training\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train with sample weights and more epochs\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,  # Increased from 5\n",
    "    batch_size=4,\n",
    "    sample_weight=sample_weights_array, # Use sample_weight instead of class_weight\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d70d7c1",
   "metadata": {},
   "source": [
    "## 9. Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a55cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Dice coefficient implementation\n",
    "def dice_score(y_true, y_pred, smooth=1e-6):\n",
    "    y_true = y_true.flatten()\n",
    "    y_pred = y_pred.flatten()\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    return (2. * intersection + smooth) / (np.sum(y_true) + np.sum(y_pred) + smooth)\n",
    "\n",
    "# Intersection over Union (IoU)\n",
    "def iou_score(y_true, y_pred, smooth=1e-6):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# Convert probability maps to class labels\n",
    "y_pred = np.argmax(y_pred_prob, axis=-1)\n",
    "\n",
    "# Compute Dice and IoU per image\n",
    "dice_scores = []\n",
    "iou_scores = []\n",
    "dice_per_class = {0: [], 1: [], 2: []}\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    # Overall binary (pore vs background)\n",
    "    dice_scores.append(dice_score(y_test[i] > 0, y_pred[i] > 0))\n",
    "    iou_scores.append(iou_score(y_test[i] > 0, y_pred[i] > 0))\n",
    "\n",
    "    # Per-class metrics\n",
    "    for class_id in [0, 1, 2]:\n",
    "        dice_per_class[class_id].append(\n",
    "            dice_score(y_test[i] == class_id, y_pred[i] == class_id)\n",
    "        )\n",
    "\n",
    "print(f'Mean Dice (overall): {np.mean(dice_scores):.4f}')\n",
    "print(f'Mean IoU (overall): {np.mean(iou_scores):.4f}')\n",
    "print(f'\\nPer-class Dice scores:')\n",
    "print(f'  Background (0): {np.mean(dice_per_class[0]):.4f}')\n",
    "print(f'  Small pores (1): {np.mean(dice_per_class[1]):.4f}')\n",
    "print(f'  Large pores (2): {np.mean(dice_per_class[2]):.4f}')\n",
    "\n",
    "# Show prediction statistics\n",
    "print(f'\\nPrediction class distribution:')\n",
    "for class_id in [0, 1, 2]:\n",
    "    count = np.sum(y_pred == class_id)\n",
    "    percentage = 100 * count / y_pred.size\n",
    "    print(f'  Class {class_id}: {count} pixels ({percentage:.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e35c89",
   "metadata": {},
   "source": [
    "## 10. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77d3e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize_mask(mask):\n",
    "    \"\"\"Convert class mask to RGB visualization\"\"\"\n",
    "    rgb = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)\n",
    "    rgb[mask == 1] = [255, 0, 0]   # Small pores → Red\n",
    "    rgb[mask == 2] = [0, 255, 0]   # Large pores → Green\n",
    "    return rgb\n",
    "\n",
    "# Visualize results\n",
    "idx = min(9, len(X_test) - 1)  # Ensure valid index\n",
    "\n",
    "image = X_test[idx].squeeze()\n",
    "gt_mask = y_test[idx]\n",
    "pred_mask = y_pred[idx]\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Microscopy Image')\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Ground Truth Mask')\n",
    "plt.imshow(colorize_mask(gt_mask))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Predicted Mask')\n",
    "plt.imshow(colorize_mask(pred_mask))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
