{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97e8d865",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549d57f7",
   "metadata": {},
   "source": [
    "## 1: Locate Dataset Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "515b002b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files found: 306\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Path to the directory containing BioEye .txt files\n",
    "DATA_DIR = \"C:\\\\Users\\\\admin\\\\Desktop\\\\HPC_ML Course\\\\RAN\"\n",
    "\n",
    "# Get full paths to all .txt files in the directory\n",
    "all_files = glob.glob(os.path.join(DATA_DIR, \"*.txt\"))\n",
    "\n",
    "print(f\"Total files found: {len(all_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6437f13b",
   "metadata": {},
   "source": [
    "## 2: Group Files by User ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d44c253a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total users found: 153\n"
     ]
    }
   ],
   "source": [
    "# Dictionary: { user_id : [file1, file2, ...] }\n",
    "user_files = {}\n",
    "\n",
    "for f in all_files:\n",
    "    # Filename format: ID_001_1.txt → extract user ID = 1\n",
    "    uid = int(os.path.basename(f).split(\"_\")[1])\n",
    "    \n",
    "    # Add file to that user's list\n",
    "    user_files.setdefault(uid, []).append(f)\n",
    "\n",
    "print(f\"Total users found: {len(user_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e99d02",
   "metadata": {},
   "source": [
    "## 3: Select a Subset of Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae872b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected users: [42, 80, 142, 192, 195, 198, 215, 259, 283, 288]\n"
     ]
    }
   ],
   "source": [
    "# Number of users to sample for demonstration\n",
    "NUM_USERS = 10\n",
    "\n",
    "num_available_users = len(user_files)\n",
    "\n",
    "if num_available_users == 0:\n",
    "    print(\"No users found. Check directory path.\")\n",
    "    SELECTED_USERS = []\n",
    "\n",
    "elif num_available_users < NUM_USERS:\n",
    "    print(f\"Only {num_available_users} users available. Using all.\")\n",
    "    SELECTED_USERS = sorted(user_files.keys())\n",
    "\n",
    "else:\n",
    "    # Randomly sample users (reproducible teaching demo)\n",
    "    SELECTED_USERS = sorted(random.sample(list(user_files.keys()), NUM_USERS))\n",
    "\n",
    "print(\"Selected users:\", SELECTED_USERS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a140b82",
   "metadata": {},
   "source": [
    " ## 4: Collect Files for Selected Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9050d25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total selected files: 20\n"
     ]
    }
   ],
   "source": [
    "# List of files corresponding to selected users\n",
    "selected_files = []\n",
    "\n",
    "for u in SELECTED_USERS:\n",
    "    selected_files.extend(user_files[u])\n",
    "\n",
    "print(f\"Total selected files: {len(selected_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f060d83",
   "metadata": {},
   "source": [
    "## 5: Load and Clean Eye-Tracking Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e98e0d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_file(path):\n",
    "    \"\"\"\n",
    "    Load a BioEye .txt file and keep only valid gaze samples.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        sep=r\"\\s+\",\n",
    "        skiprows=1,\n",
    "        header=None,\n",
    "        names=[\"SAMPLE\", \"X\", \"Y\", \"VALID\", \"XS\", \"YS\"]\n",
    "    )\n",
    "    \n",
    "    # Keep only valid gaze samples\n",
    "    df = df[df[\"VALID\"] == 1].reset_index(drop=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792520d6",
   "metadata": {},
   "source": [
    "## 6: Windowing (Temporal Segmentation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "258ed424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_by_index(df, win=6000, step=3000):\n",
    "    \"\"\"\n",
    "    Split a gaze signal into overlapping windows.\n",
    "\n",
    "    win  = window size (samples)\n",
    "    step = overlap stride (samples)\n",
    "    \"\"\"\n",
    "    return [\n",
    "        df.iloc[i:i + win]\n",
    "        for i in range(0, len(df) - win + 1, step)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2726bb27",
   "metadata": {},
   "source": [
    "## 7: Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a6f0a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(w):\n",
    "    \"\"\"\n",
    "    Extract simple statistical features from one gaze window.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute point-to-point displacement\n",
    "    dx = np.diff(w[\"X\"])\n",
    "    dy = np.diff(w[\"Y\"])\n",
    "\n",
    "    # Velocity magnitude (pixels/sample)\n",
    "    vel = np.sqrt(dx**2 + dy**2)\n",
    "\n",
    "    # Return feature vector\n",
    "    return [\n",
    "        w[\"X\"].mean(),            # Mean horizontal gaze position\n",
    "        w[\"X\"].std(),             # Std of horizontal gaze\n",
    "        w[\"Y\"].mean(),            # Mean vertical gaze position\n",
    "        w[\"Y\"].std(),             # Std of vertical gaze\n",
    "        vel.mean(),               # Mean velocity\n",
    "        vel.std(),                # Velocity variability\n",
    "        np.percentile(vel, 75),   # High-velocity behavior\n",
    "        np.percentile(vel, 90)    # Extreme velocity behavior\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e5c796",
   "metadata": {},
   "source": [
    "## 8: Build Feature Matrix (X) and Labels (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b986c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 134\n",
      "Feature dimension: 8\n",
      "Number of users: 10\n"
     ]
    }
   ],
   "source": [
    "X = []  # Feature vectors\n",
    "y = []  # Corresponding user IDs\n",
    "\n",
    "for f in selected_files:\n",
    "    # Extract user ID from filename\n",
    "    uid = int(os.path.basename(f).split(\"_\")[1])\n",
    "\n",
    "    # Load gaze data\n",
    "    df = load_file(f)\n",
    "\n",
    "    # Split into windows\n",
    "    windows = window_by_index(df)\n",
    "\n",
    "    for w in windows:\n",
    "        X.append(extract_features(w))\n",
    "        y.append(uid)\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"Total samples:\", X.shape[0])\n",
    "print(\"Feature dimension:\", X.shape[1])\n",
    "print(\"Number of users:\", len(np.unique(y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8dad49",
   "metadata": {},
   "source": [
    "## 9: Train–Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1174bec7",
   "metadata": {},
   "source": [
    "The dataset is represented as:\n",
    "\n",
    "$$\n",
    "\\mathcal{D} = \\{(\\mathbf{x}_i, y_i)\\}_{i=1}^{N}\n",
    "$$\n",
    "\n",
    "The dataset is split into two disjoint sets:\n",
    "\n",
    "$$\n",
    "\\mathcal{D}_{train} \\cup \\mathcal{D}_{test} = \\mathcal{D},\n",
    "\\quad\n",
    "\\mathcal{D}_{train} \\cap \\mathcal{D}_{test} = \\varnothing\n",
    "$$\n",
    "\n",
    "with the proportions:\n",
    "$$\n",
    "|\\mathcal{D}_{train}| = 0.7N,\n",
    "\\quad\n",
    "|\\mathcal{D}_{test}| = 0.3N\n",
    "$$\n",
    "\n",
    "Stratification preserves class proportions\n",
    "For each class $k$:\n",
    "\n",
    "$$\n",
    "P_{train}(y = k) \\approx P_{test}(y = k)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b881e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 93\n",
      "Testing samples: 41\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data while preserving class balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.30,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training samples:\", X_train.shape[0])\n",
    "print(\"Testing samples:\", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a579b3",
   "metadata": {},
   "source": [
    "Given a feature vector $\\mathbf{x}_i$, we want to predict the user identity $y_i$:\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}_i) = y_i\n",
    "$$\n",
    "\n",
    "At each node, a decision tree splits the data using a threshold:\n",
    "\n",
    "$$\n",
    "x_j \\le \\theta\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c3e43a",
   "metadata": {},
   "source": [
    "The model parameters $\\Theta$ are learned by minimizing classification error:\n",
    "\n",
    "$$\n",
    "\\Theta^* = \\arg\\min_{\\Theta}\n",
    "\\sum_{(\\mathbf{x}_i, y_i) \\in \\mathcal{D}_{train}}\n",
    "\\mathbb{I}(f_\\Theta(\\mathbf{x}_i) \\neq y_i)\n",
    "$$\n",
    "\n",
    "\n",
    "For each test sample:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = f(\\mathbf{x}_i),\n",
    "\\quad\n",
    "(\\mathbf{x}_i, y_i) \\in \\mathcal{D}_{test}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c9a3d7",
   "metadata": {},
   "source": [
    "## 10: Train Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72b14884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08db854",
   "metadata": {},
   "source": [
    "The Random Forest prediction is given by:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\operatorname{mode}\n",
    "\\left(\n",
    "h_1(\\mathbf{x}), h_2(\\mathbf{x}), \\dots, h_T(\\mathbf{x})\n",
    "\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efe263e",
   "metadata": {},
   "source": [
    "Classification accuracy is defined as:\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} =\n",
    "\\frac{1}{N}\n",
    "\\sum_{i=1}^{N}\n",
    "\\mathbb{I}(\\hat{y}_i = y_i)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6d675d",
   "metadata": {},
   "source": [
    "## 11: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "730d2533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8048780487804879\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          42       0.80      1.00      0.89         4\n",
      "          80       1.00      1.00      1.00         4\n",
      "         142       0.80      1.00      0.89         4\n",
      "         192       1.00      1.00      1.00         4\n",
      "         195       0.57      1.00      0.73         4\n",
      "         198       1.00      0.80      0.89         5\n",
      "         215       0.80      1.00      0.89         4\n",
      "         259       0.33      0.25      0.29         4\n",
      "         283       1.00      0.75      0.86         4\n",
      "         288       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.80        41\n",
      "   macro avg       0.83      0.81      0.78        41\n",
      "weighted avg       0.83      0.80      0.79        41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3757f49c",
   "metadata": {},
   "source": [
    "Precision:\n",
    "$$\n",
    "\\text{Precision} = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "Recall:\n",
    "$$\n",
    "\\text{Recall} = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "The F1-score is the harmonic mean of precision and recall:\n",
    "\n",
    "$$\n",
    "\\text{F1} =\n",
    "2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}\n",
    "{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735178fb",
   "metadata": {},
   "source": [
    "## 12: Inspect Individual Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2718b63",
   "metadata": {},
   "source": [
    "For a single test example:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_i \\rightarrow \\hat{y}_i\n",
    "$$\n",
    "\n",
    "Correct prediction if:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = y_i\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a0cbd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True user ID: 283\n",
      "Predicted user ID: 283\n"
     ]
    }
   ],
   "source": [
    "i = 1  # index of test sample\n",
    "\n",
    "print(\"True user ID:\", y_test[i])\n",
    "print(\"Predicted user ID:\", y_pred[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8416b130",
   "metadata": {},
   "source": [
    "## 13: Tabular View of Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a574285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>True_User_ID</th>\n",
       "      <th>Predicted_User_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>259</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>288</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  True_User_ID  Predicted_User_ID\n",
       "0      0           259                195\n",
       "1      1           283                283\n",
       "2      2           288                288\n",
       "3      3           198                198\n",
       "4      4           142                142"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first 5 predictions in a table\n",
    "results_df = pd.DataFrame({\n",
    "    \"Index\": range(5),\n",
    "    \"True_User_ID\": y_test[:5],\n",
    "    \"Predicted_User_ID\": y_pred[:5]\n",
    "})\n",
    "\n",
    "results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
